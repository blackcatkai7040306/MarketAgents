# LLM Agents

## Overview

This project provides utilities for parallel AI inference and prompt caching using large language models (LLMs).

## Installation

To install the `llm_agents` package in editable mode, follow these steps:

1. Clone the repository:

    ```sh
    git clone <repository_url>
    cd <repository_directory>
    ```

2. Install the package in editable mode:

    ```sh
    pip install -e .
    ```

3. Install the required dependencies:

    ```sh
    pip install -r requirements.txt
    ```

## Running Examples

You can run the examples from the `examples` folder. For instance, to run the `cache_example.py`, use the following command:

